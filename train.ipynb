{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "```bash\n",
    "sudo docker build -t maskrcnn-benchmark .\n",
    "sudo docker run \n",
    "    --runtime=nvidia -d -it \\\n",
    "    --name=maskrcnn \\\n",
    "    -v=$(pwd):/notebooks \\\n",
    "    -p=8888:8888 \\\n",
    "    --ipc=\"host\" \\\n",
    "    maskrcnn-benchmark\n",
    "sudo docker logs maskrcnn\n",
    "sudo docker start maskrcnn\n",
    "sudo docker exec -it maskrcnn /bin/bash\n",
    "```\n",
    "\n",
    "## Notes\n",
    "\n",
    "model-free vs model-based: model包含actor & critic，在critic方面，model-based有含renderer net, model-free沒有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/LearningToPaint/rllib\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0828 14:48:39.492340 139928004024064 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2019-08-28 14:48:41,197\tINFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-08-28_14-48-41_196248_1657/logs.\n",
      "2019-08-28 14:48:41,340\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:24187 to respond...\n",
      "2019-08-28 14:48:41,592\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:60879 to respond...\n",
      "2019-08-28 14:48:41,597\tINFO services.py:809 -- Starting Redis shard with 1.67 GB max memory.\n",
      "2019-08-28 14:48:41,789\tINFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-08-28_14-48-41_196248_1657/logs.\n",
      "2019-08-28 14:48:41,794\tINFO services.py:1475 -- Starting the Plasma object store with 2.51 GB memory using /dev/shm.\n",
      "2019-08-28 14:48:42,679\tINFO trial_runner.py:176 -- Starting a new experiment.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 1.6/8.4 GB\n",
      "\n",
      "2019-08-28 14:48:42,852\tWARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.\n",
      "W0828 14:48:43.087274 139928004024064 deprecation_wrapper.py:119] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/logger.py:133: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.\n",
      "\n",
      "W0828 14:48:43.088146 139928004024064 deprecation_wrapper.py:119] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/logger.py:138: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "2019-08-28 14:48:43,114\tERROR log_sync.py:34 -- Log sync requires cluster to be setup with `ray up`.\n",
      "2019-08-28 14:48:43,588\tWARNING util.py:145 -- The `start_trial` operation took 0.8190417289733887 seconds to complete, which may be a performance bottleneck.\n",
      "2019-08-28 14:48:43,749\tWARNING util.py:145 -- The `experiment_checkpoint` operation took 0.1556689739227295 seconds to complete, which may be a performance bottleneck.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2/2 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 1.6/8.4 GB\n",
      "Result logdir: /root/ray_results/PPO\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_CanvasEnv_0:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m WARNING: Logging before flag parsing goes to stderr.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m W0828 14:48:57.248260 139951960057600 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:48:59,056\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:48:59.057182: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:48:59.079718: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1296000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:48:59.080028: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5556fb481ca0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:48:59.080073: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m W0828 14:48:59.133144 139951960057600 deprecation.py:506] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Tensor(\"default_policy/Reshape:0\", shape=(?, 9, 9, 1), dtype=float32)\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m W0828 14:49:00.934835 139951960057600 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:77: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Use `tf.random.categorical` instead.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m W0828 14:49:01.026840 139951960057600 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:49:01.460943: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:49:01,860\tINFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 5) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 166) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 166) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m W0828 14:49:02.218894 139951960057600 deprecation.py:506] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:64: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m keep_dims is deprecated, use keepdims instead\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m W0828 14:49:02.241681 139951960057600 deprecation.py:506] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:69: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m keep_dims is deprecated, use keepdims instead\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m W0828 14:49:02.494894 139951960057600 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:49:09,686\tINFO rollout_worker.py:742 -- Built policy map: {'default_policy': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x7f48965eaf60>}\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:49:09,687\tINFO rollout_worker.py:743 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.DictFlatteningPreprocessor object at 0x7f48965eacc0>}\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:49:09,687\tINFO rollout_worker.py:356 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f48965ea940>}\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:49:09,822\tINFO multi_gpu_optimizer.py:93 -- LocalMultiGPUOptimizer devices ['/cpu:0']\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Tensor(\"default_policy_1/tower/Reshape:0\", shape=(?, 9, 9, 1), dtype=float32)\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Tensor(\"default_policy_1/tower_1/Reshape:0\", shape=(?, 9, 9, 1), dtype=float32, device=/device:CPU:0)\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m WARNING: Logging before flag parsing goes to stderr.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m W0828 14:49:22.532622 139833929369344 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m 2019-08-28 14:49:24,822\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m 2019-08-28 14:49:24.959619: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m 2019-08-28 14:49:25.016454: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1296000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m 2019-08-28 14:49:25.017415: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558a9f699ab0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m 2019-08-28 14:49:25.017478: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m W0828 14:49:25.092025 139833929369344 deprecation.py:506] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Tensor(\"default_policy/Reshape:0\", shape=(?, 9, 9, 1), dtype=float32)\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m W0828 14:49:26.661269 139833929369344 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:77: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Use `tf.random.categorical` instead.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m W0828 14:49:26.789503 139833929369344 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:138: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Use `tf.cast` instead.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m 2019-08-28 14:49:27.091526: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m 2019-08-28 14:49:27,481\tINFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 5) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 166) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 166) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 3) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m W0828 14:49:27.760268 139833929369344 deprecation.py:506] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:64: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m keep_dims is deprecated, use keepdims instead\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m W0828 14:49:27.806653 139833929369344 deprecation.py:506] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:69: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m keep_dims is deprecated, use keepdims instead\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m W0828 14:49:27.980784 139833929369344 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:49:43,592\tINFO trainable.py:105 -- _setup took 44.633 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m W0828 14:49:43.597346 139951960057600 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m W0828 14:49:44.618082 139833929369344 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "2019-08-28 14:49:52,929\tERROR trial_runner.py:550 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 498, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 342, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/worker.py\", line 2247, in get\n",
      "    raise value\n",
      "ray.exceptions.RayTaskError: \u001b[36mray_PPO:train()\u001b[39m (pid=1697, host=714a8423a409)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 369, in train\n",
      "    raise e\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 358, in train\n",
      "    result = Trainable.train(self)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 171, in train\n",
      "    result = self._train()\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py\", line 126, in _train\n",
      "    fetches = self.optimizer.step()\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/optimizers/multi_gpu_optimizer.py\", line 140, in step\n",
      "    self.num_envs_per_worker, self.train_batch_size)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/optimizers/rollout.py\", line 29, in collect_samples\n",
      "    next_sample = ray_get_and_free(fut_sample)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/utils/memory.py\", line 33, in ray_get_and_free\n",
      "    result = ray.get(object_ids)\n",
      "ray.exceptions.RayTaskError: \u001b[36mray_RolloutWorker:sample()\u001b[39m (pid=1696, host=714a8423a409)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 453, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 56, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 97, in get_data\n",
      "    item = next(self.rollout_provider)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 313, in _env_runner\n",
      "    soft_horizon)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/evaluation/sampler.py\", line 401, in _process_observations\n",
      "    policy_id).transform(raw_obs)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/preprocessors.py\", line 229, in transform\n",
      "    self.check_shape(observation)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
      "    self._obs_space, observation)\n",
      "ValueError: ('Observation outside expected value range', Dict(cur_im:Box(9, 9, 1), obj_status:Box(4,), target_im:Box(9, 9, 1)), {'target_im': array([[  0, 255, 255, 255, 255,   0,   0,   0,   0],\n",
      "       [  0, 255, 255, 255, 255,   0,   0,   0,   0],\n",
      "       [  0, 255, 255, 255, 255,   0,   0,   0,   0],\n",
      "       [  0, 255, 255, 255, 255,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8), 'cur_im': array([[255, 255, 255, 255,   0,   0,   0,   0,   0],\n",
      "       [255, 255, 255, 255,   0,   0,   0,   0,   0],\n",
      "       [255, 255, 255, 255,   0,   0,   0,   0,   0],\n",
      "       [255, 255, 255, 255,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8), 'obj_status': array([[0., 0., 3., 3.]], dtype=float32)})\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m 2019-08-28 14:49:52,877\tINFO rollout_worker.py:451 -- Generating sample batch of size 200\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m 2019-08-28 14:49:52,880\tINFO sampler.py:304 -- Raw obs from env: { 0: { 'agent0': { 'cur_im': np.ndarray((9, 9), dtype=uint8, min=0.0, max=255.0, mean=50.37),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m                    'obj_status': np.ndarray((1, 4), dtype=float32, min=0.0, max=3.0, mean=1.5),\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m                    'target_im': np.ndarray((9, 9), dtype=uint8, min=0.0, max=255.0, mean=50.37)}}}\n",
      "\u001b[2m\u001b[36m(pid=1696)\u001b[0m 2019-08-28 14:49:52,884\tINFO sampler.py:305 -- Info return from env: {0: {'agent0': None}}\n",
      "\u001b[2m\u001b[36m(pid=1697)\u001b[0m 2019-08-28 14:49:52,904\tINFO trainer.py:366 -- Worker crashed during call to train(). To attempt to continue training without the failed worker, set `'ignore_worker_failures': True`.\n",
      "2019-08-28 14:49:53,314\tWARNING util.py:145 -- The `experiment_checkpoint` operation took 0.3674428462982178 seconds to complete, which may be a performance bottleneck.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 2.1/8.4 GB\n",
      "Result logdir: /root/ray_results/PPO\n",
      "Number of trials: 1 ({'ERROR': 1})\n",
      "ERROR trials:\n",
      " - PPO_CanvasEnv_0:\tERROR, 1 failures: /root/ray_results/PPO/PPO_CanvasEnv_0_2019-08-28_14-48-42uh0ik3s8/error_2019-08-28_14-49-52.txt\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 2.1/8.4 GB\n",
      "Result logdir: /root/ray_results/PPO\n",
      "Number of trials: 1 ({'ERROR': 1})\n",
      "ERROR trials:\n",
      " - PPO_CanvasEnv_0:\tERROR, 1 failures: /root/ray_results/PPO/PPO_CanvasEnv_0_2019-08-28_14-48-42uh0ik3s8/error_2019-08-28_14-49-52.txt\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"canvas_env.py\", line 170, in <module>\n",
      "    \"num_workers\": 1,  # parallelism\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/tune.py\", line 262, in run\n",
      "    raise TuneError(\"Trials did not complete\", errored_trials)\n",
      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_CanvasEnv_0])\n"
     ]
    }
   ],
   "source": [
    "# !pip install ray \n",
    "# ray[rllib] ray[debug] pandas\n",
    "\n",
    "%cd /notebooks/LearningToPaint/rllib\n",
    "!python canvas_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install openai baselines and other required packages\n",
    "# !pip install gym tensorflow\n",
    "\n",
    "# !apt-get update && apt-get -y install cmake libopenmpi-dev python3-dev zlib1g-dev\n",
    "# %cd /notebooks/baselines\n",
    "# # !git clone https://github.com/openai/baselines.git  # use github-desktop to clone repository\n",
    "# !pip install -e .\n",
    "\n",
    "# # install local gym-canvas as package\n",
    "# %cd /notebooks/LearningToPaint/gym-canvas\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2mAkgRjwwuf"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail\n",
      "Tuple\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 254, in <module>\n",
      "    main()\n",
      "  File \"main.py\", line 55, in main\n",
      "    base_kwargs={\"recurrent\": args.recurrent_policy},\n",
      "  File \"/notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail/a2c_ppo_acktr/model.py\", line 41, in __init__\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail\n",
    "!python main.py --env-name \"gym_canvas:canvas-v0\" --num-processes 1 --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-steps 5 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01\n",
    "\n",
    "# !python baseline/train_renderer.py\n",
    "# !tensorboard --logdir train_log --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train RL\n",
    "\n",
    "* make data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory './model': File exists\n",
      "Renderer model loaded.\n",
      "observation_space (1, 128, 128, 7) action_space 13\n",
      "\u001b[98m #0: steps:4 interval_time:0.22 train_time:24.56\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000007: mean_reward:0.288 mean_dist:0.201 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #1: steps:8 interval_time:2.69 train_time:34.23\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000011: mean_reward:-8.902 mean_dist:0.619 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #2: steps:12 interval_time:2.55 train_time:43.24\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000015: mean_reward:-7.753 mean_dist:0.417 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #3: steps:16 interval_time:2.68 train_time:55.46\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000019: mean_reward:-1.631 mean_dist:0.326 var_dist:0.000\u001b[00m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python baseline/train.py --max_step=4 --env_batch=1 --warmup=1 --validate_interval=1 --debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renderer model loaded.\n",
      "step 0: loss 9167.975586\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"baseline/train_supervised.py\", line 84, in <module>\n",
      "    train(args.batch_size, args.episode_steps)"
     ]
    }
   ],
   "source": [
    "!python baseline/train_supervised.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "learningtopaint.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
