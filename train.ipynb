{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steup\n",
    "```bash\n",
    "sudo docker run \\\n",
    "    -it --rm \\\n",
    "    -v /Users/chi/Documents/GitHub:/workspace \\\n",
    "    -p 8888:8888 \\\n",
    "    -p 6006:6006 \\\n",
    "    --ipc=\"host\" \\\n",
    "    pytorch/pytorch:1.2-cuda10.0-cudnn7-devel\n",
    "\n",
    "sudo docker run \\\n",
    "    --runtime=nvidia \\\n",
    "    -it --rm \\\n",
    "    -v /home/chi/Documents:/workspace \\\n",
    "    -p 8888:8888 \\\n",
    "    -p 6006:6006 \\\n",
    "    --ipc=\"host\" \\\n",
    "    pytorch/pytorch:1.2-cuda10.0-cudnn7-devel\n",
    "\n",
    "-it -d --rm\n",
    "tensorflow/tensorflow:2.0.0rc0-py3-jupyter\n",
    "```\n",
    "\n",
    "Jupyter notebook\n",
    "```bash\n",
    "cd /workspace\n",
    "conda install -c conda-forge jupyterlab\n",
    "jupyter notebook --allow-root -y --no-browser --ip=0.0.0.0 --port=8888\n",
    "```\n",
    "\n",
    "@Deprecated\n",
    "```bash\n",
    "sudo docker run \\\n",
    "    -it --rm \\\n",
    "    -v /Users/chi/Documents/GitHub:/tf \\\n",
    "    -p 8888:8888 \\\n",
    "    -p 6006:6006 \\\n",
    "    --ipc=\"host\" \\\n",
    "    tensorflow/tensorflow:nightly-py3-jupyter\n",
    "\n",
    "sudo docker run \\\n",
    "    --runtime=nvidia \\\n",
    "    -it --rm \\\n",
    "    -v /home/chi/Documents:/tf \\\n",
    "    -p 8888:8888 \\\n",
    "    -p 6006:6006 \\\n",
    "    --ipc=\"host\" \\\n",
    "    tensorflow/tensorflow:nightly-gpu-py3-jupyter\n",
    "```\n",
    "\n",
    "@Deprecated\n",
    "```bash\n",
    "sudo docker build .\n",
    "sudo docker run \n",
    "    --runtime=nvidia -d -it \\\n",
    "    --name=maskrcnn \\\n",
    "    -v=$(pwd):/notebooks \\\n",
    "    -p=8888:8888 \\\n",
    "    --ipc=\"host\" \\\n",
    "    maskrcnn-benchmark\n",
    "sudo docker logs maskrcnn\n",
    "sudo docker start maskrcnn\n",
    "sudo docker exec -it maskrcnn /bin/bash\n",
    "```\n",
    "\n",
    "Notes\n",
    "- model-free vs model-based: model包含actor & critic，在critic方面，model-based有含renderer net, model-free沒有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K     |################################| 109.2MB 4.8MB/s eta 0:00:01   |                                | 583kB 641kB/s eta 0:02:50     |                                | 1.4MB 641kB/s eta 0:02:49     |#                               | 3.9MB 4.3MB/s eta 0:00:25     |#                               | 4.8MB 4.3MB/s eta 0:00:25     |#                               | 5.8MB 4.3MB/s eta 0:00:25     |###                             | 11.1MB 4.8MB/s eta 0:00:21     |###                             | 11.4MB 4.8MB/s eta 0:00:21     |#######                         | 24.1MB 4.2MB/s eta 0:00:21     |#######                         | 24.7MB 4.2MB/s eta 0:00:20     |#######                         | 25.2MB 4.2MB/s eta 0:00:20     |#########                       | 31.5MB 6.8MB/s eta 0:00:12     |#########                       | 33.3MB 5.8MB/s eta 0:00:14     |##########                      | 37.2MB 5.5MB/s eta 0:00:14     |###########                     | 39.4MB 5.5MB/s eta 0:00:13     |############                    | 41.4MB 5.5MB/s eta 0:00:13     |############                    | 42.0MB 5.2MB/s eta 0:00:13     |############                    | 43.0MB 5.2MB/s eta 0:00:13     |#############                   | 46.4MB 5.2MB/s eta 0:00:13     |#############                   | 47.3MB 8.8MB/s eta 0:00:07     |##############                  | 49.4MB 8.8MB/s eta 0:00:07     |##############                  | 51.1MB 8.8MB/s eta 0:00:07     |###############                 | 51.7MB 8.8MB/s eta 0:00:07     |###############                 | 52.6MB 8.8MB/s eta 0:00:07     |################                | 56.8MB 3.9MB/s eta 0:00:14     |#################               | 58.1MB 7.5MB/s eta 0:00:07     |#################               | 59.0MB 7.5MB/s eta 0:00:07     |#################               | 61.0MB 7.5MB/s eta 0:00:07     |#################               | 61.3MB 7.5MB/s eta 0:00:07     |##################              | 62.0MB 7.5MB/s eta 0:00:07     |##################              | 62.3MB 7.5MB/s eta 0:00:07     |##################              | 62.5MB 7.5MB/s eta 0:00:07     |##################              | 62.5MB 7.5MB/s eta 0:00:07     |##################              | 63.2MB 384kB/s eta 0:02:00     |####################            | 70.6MB 6.7MB/s eta 0:00:06     |#####################           | 72.0MB 6.7MB/s eta 0:00:06     |#######################         | 79.5MB 8.1MB/s eta 0:00:04     |#######################         | 81.4MB 8.1MB/s eta 0:00:04     |##########################      | 89.6MB 5.5MB/s eta 0:00:04     |##########################      | 91.0MB 5.5MB/s eta 0:00:04     |###########################     | 95.2MB 2.8MB/s eta 0:00:06     |############################    | 95.7MB 2.8MB/s eta 0:00:05     |############################    | 96.3MB 2.8MB/s eta 0:00:05     |############################    | 96.6MB 7.6MB/s eta 0:00:02     |############################    | 97.1MB 7.6MB/s eta 0:00:02     |############################    | 97.4MB 7.6MB/s eta 0:00:02     |############################    | 98.6MB 7.6MB/s eta 0:00:02     |#############################   | 102.1MB 7.6MB/s eta 0:00:01     |##############################  | 103.8MB 6.5MB/s eta 0:00:01     |##############################  | 104.4MB 6.5MB/s eta 0:00:01     |##############################  | 104.7MB 6.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.33.4)\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |################################| 51kB 7.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl (52kB)\n",
      "\u001b[K     |################################| 61kB 3.7MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/0d/7cbf64cac3f93617a2b6b079c0182e4a83a3e7a8964d3b0cc3d9758ba002/absl-py-0.8.0.tar.gz (102kB)\n",
      "\u001b[K     |################################| 112kB 13.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.6.1 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/d5/e18969c31e24300551373d96286383d861332cafbf2bfea6d6453fcf2923/protobuf-3.9.2-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K     |################################| 1.2MB 6.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |################################| 3.2MB 6.1MB/s eta 0:00:01     |##########                      | 1.0MB 6.1MB/s eta 0:00:01     |###############                 | 1.5MB 6.1MB/s eta 0:00:01     |######################          | 2.2MB 6.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.16.5)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K     |################################| 491kB 12.1MB/s eta 0:00:01     |####################            | 317kB 12.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.12.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K     |################################| 51kB 3.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/04/4e36c33f8eb5c5b6c622a1f4859352a6acca7ab387257d4b3c191d23ec1d/gast-0.3.2.tar.gz\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/95/4a5b112616e2f1261759eabaaec06791f0b685d72b9516009742fd93d0df/grpcio-1.24.0-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
      "\u001b[K     |################################| 2.3MB 6.6MB/s eta 0:00:01     |############                    | 880kB 6.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py (from keras-applications>=1.0.6->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |################################| 2.9MB 32.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K     |################################| 92kB 7.5MB/s eta 0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "\u001b[K     |################################| 327kB 3.9MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: absl-py, termcolor, gast\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.8.0-cp36-none-any.whl size=120989 sha256=f1e8b235884252b0e13f0f66db1788cba82ecf8e2613fe9b32d6663061d2b239\n",
      "  Stored in directory: /root/.cache/pip/wheels/9a/1e/7a/456008eb5e47fd5de792c6139df6d5b3d5f71d51c6a0b94799\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-cp36-none-any.whl size=4833 sha256=f0e5465e0397fe9ee405f52fa3d1f978299990de1e970c6c730e5f0834a86108\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.3.2-cp36-none-any.whl size=9679 sha256=68733be1b25fd024e574b5b3a75ae08f668891a772c4812e57fef639b00c090c\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/38/c6/234dc39b4f6951a0768fbc02d5b7207137a5b1d9094f0d54bf\n",
      "Successfully built absl-py termcolor gast\n",
      "Installing collected packages: h5py, keras-applications, google-pasta, astor, absl-py, protobuf, markdown, werkzeug, grpcio, tensorboard, tensorflow-estimator, termcolor, keras-preprocessing, gast, tensorflow\n",
      "Successfully installed absl-py-0.8.0 astor-0.8.0 gast-0.3.2 google-pasta-0.1.7 grpcio-1.24.0 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 protobuf-3.9.2 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 werkzeug-0.16.0\n",
      "Collecting ray[rllib]\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/e7/37a7f8dc2b1f96c760a3950d8bb5a3f14066f1699f5d004f0f6462d880c9/ray-0.7.5-cp36-cp36m-manylinux1_x86_64.whl (74.9MB)\n",
      "\u001b[K     |################################| 74.9MB 1.1MB/s eta 0:00:012   |#                               | 3.4MB 779kB/s eta 0:01:32     |###                             | 7.1MB 8.3MB/s eta 0:00:09     |####                            | 10.6MB 8.3MB/s eta 0:00:08     |########                        | 18.8MB 6.7MB/s eta 0:00:09     |########                        | 19.0MB 2.7MB/s eta 0:00:21     |########                        | 19.3MB 2.7MB/s eta 0:00:21     |########                        | 19.6MB 2.7MB/s eta 0:00:21     |#######################         | 54.1MB 10.0MB/s eta 0:00:03     |########################        | 57.4MB 10.0MB/s eta 0:00:02     |###########################     | 63.2MB 9.0MB/s eta 0:00:02     |###########################     | 63.9MB 343kB/s eta 0:00:32     |###########################     | 64.3MB 343kB/s eta 0:00:31     |###########################     | 64.7MB 343kB/s eta 0:00:30     |#############################   | 69.6MB 343kB/s eta 0:00:16     |##############################  | 72.5MB 1.1MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.6/site-packages (5.6.3)\n",
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/9b/52e228545d14f14bb2a1622e225f38463c8726645165e1cb7dde95bfe6d4/pandas-0.25.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
      "\u001b[K     |################################| 10.5MB 7.4MB/s eta 0:00:01    |#######                         | 2.5MB 4.9MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (2.22.0)\n",
      "Requirement already satisfied: six>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from ray[rllib]) (1.12.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from ray[rllib]) (3.0.12)\n",
      "Collecting pytest (from ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/e1/2f229554e5c273962fae8b286395d5bbcc7bef276d2b40e1bad954993db2/pytest-5.1.3-py3-none-any.whl (224kB)\n",
      "\u001b[K     |################################| 225kB 8.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from ray[rllib]) (5.1.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.6/site-packages (from ray[rllib]) (3.9.2)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.6/site-packages (from ray[rllib]) (3.0.2)\n",
      "Collecting funcsigs (from ray[rllib])\n",
      "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Collecting colorama (from ray[rllib])\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
      "Collecting redis>=3.3.2 (from ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/64/b1e90af9bf0c7f6ef55e46b81ab527b33b785824d65300bb65636534b530/redis-3.3.8-py2.py3-none-any.whl (66kB)\n",
      "\u001b[K     |################################| 71kB 6.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.6/site-packages (from ray[rllib]) (1.16.5)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from ray[rllib]) (7.0)\n",
      "Collecting gym[atari]; extra == \"rllib\" (from ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/75/9e841bc2bc75128e0b65c3d5255d0bd16becb9d8f7120b965d41b8e70041/gym-0.14.0.tar.gz (1.6MB)\n",
      "\u001b[K     |################################| 1.6MB 4.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy; extra == \"rllib\" in /opt/conda/lib/python3.6/site-packages (from ray[rllib]) (1.3.1)\n",
      "Collecting opencv-python-headless; extra == \"rllib\" (from ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/dc/b250f03ab68068033fd2356428c1357431d8ebc6a26405098e0f27c94f7a/opencv_python_headless-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (22.1MB)\n",
      "\u001b[K     |################################| 22.1MB 13.5MB/s eta 0:00:01   |                                | 430kB 5.5MB/s eta 0:00:04     |#                               | 1.0MB 5.5MB/s eta 0:00:04     |#                               | 1.2MB 5.5MB/s eta 0:00:04     |##                              | 1.8MB 5.5MB/s eta 0:00:04     |###                             | 2.6MB 5.5MB/s eta 0:00:04     |######                          | 4.4MB 1.5MB/s eta 0:00:12     |###############                 | 10.6MB 7.6MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting lz4; extra == \"rllib\" (from ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/5e/cedd32c203ce0303188b0c7ff8388bba3c33e4bf6da21ae789962c4fb2e7/lz4-2.2.1-cp36-cp36m-manylinux1_x86_64.whl (395kB)\n",
      "\u001b[K     |################################| 399kB 5.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas) (2019.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests) (2019.9.11)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from pytest->ray[rllib]) (0.1.7)\n",
      "Collecting packaging (from pytest->ray[rllib])\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/94/9672c2d4b126e74c4496c6b3c58a8b51d6419267be9e70660ba23374c875/packaging-19.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from pytest->ray[rllib]) (19.1.0)\n",
      "Collecting pluggy<1.0,>=0.12 (from pytest->ray[rllib])\n",
      "  Downloading https://files.pythonhosted.org/packages/92/c7/48439f7d5fd6bddb4c04b850bb862b42e3e2b98570040dfaf68aedd8114b/pluggy-0.13.0-py2.py3-none-any.whl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting atomicwrites>=1.0 (from pytest->ray[rllib])\n",
      "  Downloading https://files.pythonhosted.org/packages/52/90/6155aa926f43f2b2a22b01be7241be3bfd1ceaf7d0b3267213e8127d41f4/atomicwrites-1.3.0-py2.py3-none-any.whl\n",
      "Collecting importlib-metadata>=0.12; python_version < \"3.8\" (from pytest->ray[rllib])\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/d2/40b3fa882147719744e6aa50ac39cf7a22a913cbcba86a0371176c425a3b/importlib_metadata-0.23-py2.py3-none-any.whl\n",
      "Collecting py>=1.5.0 (from pytest->ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/bc/394ad449851729244a97857ee14d7cba61ddb268dce3db538ba2f2ba1f0f/py-1.8.0-py2.py3-none-any.whl (83kB)\n",
      "\u001b[K     |################################| 92kB 6.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting more-itertools>=4.0.0 (from pytest->ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/dc/3241eef99eb45f1def35cf93af35d1cf9ef4c0991792583b8f33ea41b092/more_itertools-7.2.0-py3-none-any.whl (57kB)\n",
      "\u001b[K     |################################| 61kB 4.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.8.0->ray[rllib]) (41.0.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema->ray[rllib]) (0.15.4)\n",
      "Collecting pyglet<=1.3.2,>=1.2.0 (from gym[atari]; extra == \"rllib\"->ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
      "\u001b[K     |################################| 1.0MB 4.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle~=1.2.0 (from gym[atari]; extra == \"rllib\"->ray[rllib])\n",
      "  Downloading https://files.pythonhosted.org/packages/c1/49/334e279caa3231255725c8e860fa93e72083567625573421db8875846c14/cloudpickle-1.2.2-py2.py3-none-any.whl\n",
      "Collecting atari_py~=0.2.0 (from gym[atari]; extra == \"rllib\"->ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/45/c2f6523aed89db6672b241fa1aafcfa54126c564be769c1360d298f03852/atari_py-0.2.6-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
      "\u001b[K     |################################| 2.8MB 11.1MB/s eta 0:00:01     |############################### | 2.7MB 11.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (6.1.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.6/site-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (4.1.1.26)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->pytest->ray[rllib]) (2.4.2)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->ray[rllib])\n",
      "  Downloading https://files.pythonhosted.org/packages/74/3d/1ee25a26411ba0401b43c6376d2316a71addcc72ef8690b101b4ea56d76a/zipp-0.6.0-py2.py3-none-any.whl\n",
      "Collecting future (from pyglet<=1.3.2,>=1.2.0->gym[atari]; extra == \"rllib\"->ray[rllib])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/52/e20466b85000a181e1e144fd8305caf2cf475e2f9674e797b222f8105f5f/future-0.17.1.tar.gz (829kB)\n",
      "\u001b[K     |################################| 829kB 9.3MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: gym, future\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.14.0-cp36-none-any.whl size=1637526 sha256=ffdf9a318039e982fe72493f5a10fc397ab463347ec81e7e067b8377dda44e2a\n",
      "  Stored in directory: /root/.cache/pip/wheels/7e/53/f6/c0cd3c9bf953f35c0aee7fa62ea209371e92f5e5cced3245ba\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.17.1-cp36-none-any.whl size=488730 sha256=14b23685ee6ea61cc18d74bc927ea79623189578cae0a30bdc09c966078ad900\n",
      "  Stored in directory: /root/.cache/pip/wheels/0c/61/d2/d6b7317325828fbb39ee6ad559dbe4664d0896da4721bf379e\n",
      "Successfully built gym future\n",
      "Installing collected packages: packaging, more-itertools, zipp, importlib-metadata, pluggy, atomicwrites, py, pytest, funcsigs, colorama, redis, future, pyglet, cloudpickle, atari-py, gym, opencv-python-headless, lz4, ray, pandas\n",
      "Successfully installed atari-py-0.2.6 atomicwrites-1.3.0 cloudpickle-1.2.2 colorama-0.4.1 funcsigs-1.0.2 future-0.17.1 gym-0.14.0 importlib-metadata-0.23 lz4-2.2.1 more-itertools-7.2.0 opencv-python-headless-4.1.1.26 packaging-19.2 pandas-0.25.1 pluggy-0.13.0 py-1.8.0 pyglet-1.3.2 pytest-5.1.3 ray-0.7.5 redis-3.3.8 zipp-0.6.0\n"
     ]
    }
   ],
   "source": [
    "# !apt-get update && apt-get install -y libglib2.0-0 libsm6 libxrender-dev libxext6 && apt-get clean && rm -rf /var/lib/apt/lists/*\n",
    "!pip install --upgrade tensorflow\n",
    "!conda install -c anaconda tensorflow-gpu\n",
    "!pip install ray[rllib] ray[debug] psutil pandas requests\n",
    "# !pip install torchsummary\n",
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/LearningToPaint/rllib\n",
      "2019-09-28 02:42:29,599\tWARNING worker.py:1426 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2019-09-28 02:42:29,601\tINFO resource_spec.py:205 -- Starting Ray with 5.37 GiB memory available for workers and up to 2.69 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/5.37 GiB heap, 0.0/1.81 GiB objects\n",
      "Memory usage on this node: 1.0/11.7 GiB\n",
      "\n",
      "2019-09-28 02:42:30,315\tERROR log_sync.py:28 -- Log sync requires rsync to be installed.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/5.37 GiB heap, 0.0/1.81 GiB objects\n",
      "Memory usage on this node: 1.0/11.7 GiB\n",
      "Result logdir: /root/ray_results/PPO\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_SimpleCorridor_0:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:35,714\tINFO trainer.py:344 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:37,600\tINFO rollout_worker.py:768 -- Built policy map: {'default_policy': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x7fd367dddef0>}\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:37,601\tINFO rollout_worker.py:769 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.DictFlatteningPreprocessor object at 0x7fd367dddda0>}\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:37,601\tINFO rollout_worker.py:370 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7fd367dddc50>}\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:37,631\tINFO multi_gpu_optimizer.py:93 -- LocalMultiGPUOptimizer devices ['/cpu:0']\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m 2019-09-28 02:42:44,034\tINFO rollout_worker.py:467 -- Generating sample batch of size 200\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m 2019-09-28 02:42:44,034\tINFO sampler.py:310 -- Raw obs from env: {0: {'agent0': {'a': [0], 'b': [0]}}}\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m 2019-09-28 02:42:44,035\tINFO sampler.py:311 -- Info return from env: {0: {'agent0': None}}\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m 2019-09-28 02:42:44,035\tINFO sampler.py:409 -- Preprocessed obs: np.ndarray((2,), dtype=float64, min=0.0, max=0.0, mean=0.0)\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m 2019-09-28 02:42:44,035\tINFO sampler.py:413 -- Filtered obs: np.ndarray((2,), dtype=float64, min=0.0, max=0.0, mean=0.0)\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m 2019-09-28 02:42:44,036\tINFO sampler.py:528 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                                   'info': None,\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                                   'obs': np.ndarray((2,), dtype=float64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                                   'prev_action': np.ndarray((2,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                                   'prev_reward': 0.0,\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m 2019-09-28 02:42:44,036\tINFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m 2019-09-28 02:42:44,084\tINFO sampler.py:555 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m { 'default_policy': ( { 'data': { 'batches': [ np.ndarray((1,), dtype=int64, min=1.0, max=1.0, mean=1.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                                                np.ndarray((1,), dtype=int64, min=1.0, max=1.0, mean=1.0)]},\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'type': 'TupleActions'},\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                       { 'action_logp': np.ndarray((1,), dtype=float32, min=-2.079, max=-2.079, mean=-2.079),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'action_prob': np.ndarray((1,), dtype=float32, min=0.125, max=0.125, mean=0.125),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'behaviour_logits': np.ndarray((1, 6), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0)})}\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m 2019-09-28 02:42:44,100\tINFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m { 'agent0': { 'data': { 'action_logp': np.ndarray((8,), dtype=float32, min=-2.365, max=-1.937, mean=-2.147),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'action_prob': np.ndarray((8,), dtype=float32, min=0.094, max=0.144, mean=0.118),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'actions': np.ndarray((8, 2), dtype=int64, min=0.0, max=3.0, mean=1.375),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'advantages': np.ndarray((8,), dtype=float32, min=-0.092, max=0.961, mean=0.59),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'agent_index': np.ndarray((8,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'behaviour_logits': np.ndarray((8, 6), dtype=float32, min=-0.561, max=0.945, mean=0.053),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'dones': np.ndarray((8,), dtype=bool, min=0.0, max=1.0, mean=0.125),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'eps_id': np.ndarray((8,), dtype=int64, min=1344345966.0, max=1344345966.0, mean=1344345966.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'infos': np.ndarray((8,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'new_obs': np.ndarray((8, 2), dtype=float32, min=0.0, max=5.0, mean=2.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'obs': np.ndarray((8, 2), dtype=float32, min=0.0, max=4.0, mean=1.375),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'prev_actions': np.ndarray((8, 2), dtype=int64, min=0.0, max=3.0, mean=1.188),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'prev_rewards': np.ndarray((8,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'rewards': np.ndarray((8,), dtype=int64, min=0.0, max=1.0, mean=0.125),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         't': np.ndarray((8,), dtype=int64, min=0.0, max=7.0, mean=3.5),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'unroll_id': np.ndarray((8,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'value_targets': np.ndarray((8,), dtype=float32, min=0.932, max=1.0, mean=0.966),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m                         'vf_preds': np.ndarray((8,), dtype=float32, min=0.0, max=1.092, mean=0.375)},\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m 2019-09-28 02:42:44,503\tINFO rollout_worker.py:501 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m { 'data': { 'action_logp': np.ndarray((200,), dtype=float32, min=-2.477, max=-1.559, mean=-2.092),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'action_prob': np.ndarray((200,), dtype=float32, min=0.084, max=0.21, mean=0.125),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'actions': np.ndarray((200, 2), dtype=int64, min=0.0, max=3.0, mean=1.015),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'advantages': np.ndarray((200,), dtype=float32, min=-0.281, max=0.961, mean=0.46),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'behaviour_logits': np.ndarray((200, 6), dtype=float32, min=-0.561, max=0.945, mean=0.054),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'dones': np.ndarray((200,), dtype=bool, min=0.0, max=1.0, mean=0.05),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'eps_id': np.ndarray((200,), dtype=int64, min=8120344.0, max=1537491382.0, mean=627808923.87),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'infos': np.ndarray((200,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'new_obs': np.ndarray((200, 2), dtype=float32, min=0.0, max=5.0, mean=1.66),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'obs': np.ndarray((200, 2), dtype=float32, min=0.0, max=4.0, mean=1.405),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'prev_actions': np.ndarray((200, 2), dtype=int64, min=0.0, max=3.0, mean=0.945),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'prev_rewards': np.ndarray((200,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'rewards': np.ndarray((200,), dtype=int64, min=0.0, max=1.0, mean=0.05),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             't': np.ndarray((200,), dtype=int64, min=0.0, max=52.0, mean=14.365),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'value_targets': np.ndarray((200,), dtype=float32, min=0.252, max=1.0, mean=0.844),\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=0.0, max=1.092, mean=0.384)},\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=3090)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,779\tINFO tf_policy.py:358 -- Optimizing variable <tf.Variable 'default_policy/dense/kernel:0' shape=(2, 16) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,779\tINFO tf_policy.py:358 -- Optimizing variable <tf.Variable 'default_policy/dense/bias:0' shape=(16,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,779\tINFO tf_policy.py:358 -- Optimizing variable <tf.Variable 'default_policy/dense_1/kernel:0' shape=(16, 32) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,780\tINFO tf_policy.py:358 -- Optimizing variable <tf.Variable 'default_policy/dense_1/bias:0' shape=(32,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,780\tINFO tf_policy.py:358 -- Optimizing variable <tf.Variable 'default_policy/dense_2/kernel:0' shape=(32, 64) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,780\tINFO tf_policy.py:358 -- Optimizing variable <tf.Variable 'default_policy/dense_2/bias:0' shape=(64,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,780\tINFO tf_policy.py:358 -- Optimizing variable <tf.Variable 'default_policy/dense_3/kernel:0' shape=(64, 6) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,780\tINFO tf_policy.py:358 -- Optimizing variable <tf.Variable 'default_policy/dense_3/bias:0' shape=(6,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,780\tINFO tf_policy.py:358 -- Optimizing variable <tf.Variable 'default_policy/dense_4/kernel:0' shape=(64, 1) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,780\tINFO tf_policy.py:358 -- Optimizing variable <tf.Variable 'default_policy/dense_4/bias:0' shape=(1,) dtype=float32>\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,784\tINFO multi_gpu_impl.py:146 -- Training on concatenated sample batches:\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m { 'inputs': [ np.ndarray((4000, 2), dtype=int64, min=0.0, max=3.0, mean=0.905),\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m               np.ndarray((4000,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m               np.ndarray((4000, 2), dtype=float32, min=0.0, max=4.0, mean=1.355),\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m               np.ndarray((4000,), dtype=float32, min=-2.477, max=-1.559, mean=-2.065),\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m               np.ndarray((4000, 2), dtype=int64, min=0.0, max=3.0, mean=0.942),\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m               np.ndarray((4000,), dtype=float32, min=-3.828, max=1.787, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m               np.ndarray((4000, 6), dtype=float32, min=-0.561, max=0.945, mean=0.053),\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m               np.ndarray((4000, 2), dtype=float32, min=0.0, max=4.0, mean=1.355),\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m               np.ndarray((4000, 2), dtype=int64, min=0.0, max=3.0, mean=0.905),\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m               np.ndarray((4000,), dtype=float32, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m               np.ndarray((4000,), dtype=float32, min=-0.0, max=1.081, mean=0.738),\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m               np.ndarray((4000,), dtype=float32, min=0.0, max=1.092, mean=0.37)],\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m   'placeholders': [ <tf.Tensor 'default_policy/action:0' shape=(?, 2) dtype=int64>,\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m                     <tf.Tensor 'default_policy/action_logp:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 2) dtype=int64>,\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m                     <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 6) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m                     <tf.Tensor 'default_policy/action:0' shape=(?, 2) dtype=int64>,\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m   'state_inputs': []}\n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3089)\u001b[0m 2019-09-28 02:42:50,784\tINFO multi_gpu_impl.py:191 -- Divided 4000 rollout sequences, each of length 1, among 1 devices.\n",
      "Result for PPO_SimpleCorridor_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-09-28_02-42-54\n",
      "  done: false\n",
      "  episode_len_mean: 28.86466165413534\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: 1.0\n",
      "  episode_reward_min: 1.0\n",
      "  episodes_this_iter: 133\n",
      "  episodes_total: 133\n",
      "  experiment_id: 3f7f7c9bfdbb4863a4914574f0ab520a\n",
      "  hostname: b95a43ffdfe3\n",
      "  info:\n",
      "    grad_time_ms: 3750.945\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.0474140644073486\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.014882167801260948\n",
      "        policy_loss: -0.021486856043338776\n",
      "        total_loss: 0.09601322561502457\n",
      "        vf_explained_var: -0.3530293107032776\n",
      "        vf_loss: 0.11452364921569824\n",
      "    load_time_ms: 102.668\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 3968\n",
      "    sample_time_ms: 6789.339\n",
      "    update_time_ms: 726.118\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  pid: 3089\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.07094636138633799\n",
      "    mean_inference_ms: 1.1971662474167226\n",
      "    mean_processing_ms: 0.3263837723277921\n",
      "  time_since_restore: 11.468574523925781\n",
      "  time_this_iter_s: 11.468574523925781\n",
      "  time_total_s: 11.468574523925781\n",
      "  timestamp: 1569638574\n",
      "  timesteps_since_restore: 4000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 9d9d9a64\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/5.37 GiB heap, 0.0/1.81 GiB objects\n",
      "Memory usage on this node: 1.5/11.7 GiB\n",
      "Result logdir: /root/ray_results/PPO\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_SimpleCorridor_0:\tRUNNING, [2 CPUs, 0 GPUs], [pid=3089], 11 s, 1 iter, 4000 ts, 1 rew\n",
      "\n",
      "Result for PPO_SimpleCorridor_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-09-28_02-43-04\n",
      "  done: false\n",
      "  episode_len_mean: 17.617021276595743\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: 1.0\n",
      "  episode_reward_min: 1.0\n",
      "  episodes_this_iter: 235\n",
      "  episodes_total: 368\n",
      "  experiment_id: 3f7f7c9bfdbb4863a4914574f0ab520a\n",
      "  hostname: b95a43ffdfe3\n",
      "  info:\n",
      "    grad_time_ms: 3389.591\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 2.0010335445404053\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.015617815777659416\n",
      "        policy_loss: -0.020579658448696136\n",
      "        total_loss: 0.002501566894352436\n",
      "        vf_explained_var: 0.020985273644328117\n",
      "        vf_loss: 0.01995766907930374\n",
      "    load_time_ms: 52.299\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 7936\n",
      "    sample_time_ms: 6502.812\n",
      "    update_time_ms: 370.607\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  pid: 3089\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.06823887781506256\n",
      "    mean_inference_ms: 1.147308493834587\n",
      "    mean_processing_ms: 0.31714143790002025\n",
      "  time_since_restore: 20.744837999343872\n",
      "  time_this_iter_s: 9.27626347541809\n",
      "  time_total_s: 20.744837999343872\n",
      "  timestamp: 1569638584\n",
      "  timesteps_since_restore: 8000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 2\n",
      "  trial_id: 9d9d9a64\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2/2 CPUs, 0/0 GPUs, 0.0/5.37 GiB heap, 0.0/1.81 GiB objects\n",
      "Memory usage on this node: 1.5/11.7 GiB\n",
      "Result logdir: /root/ray_results/PPO\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_SimpleCorridor_0:\tRUNNING, [2 CPUs, 0 GPUs], [pid=3089], 20 s, 2 iter, 8000 ts, 1 rew\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_SimpleCorridor_0:\n",
      "  custom_metrics: {}\n",
      "  date: 2019-09-28_02-43-13\n",
      "  done: true\n",
      "  episode_len_mean: 11.474285714285715\n",
      "  episode_reward_max: 1.0\n",
      "  episode_reward_mean: 1.0\n",
      "  episode_reward_min: 1.0\n",
      "  episodes_this_iter: 350\n",
      "  episodes_total: 718\n",
      "  experiment_id: 3f7f7c9bfdbb4863a4914574f0ab520a\n",
      "  hostname: b95a43ffdfe3\n",
      "  info:\n",
      "    grad_time_ms: 3267.388\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 1.912728190422058\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.022930799052119255\n",
      "        policy_loss: -0.04444146528840065\n",
      "        total_loss: -0.036909643560647964\n",
      "        vf_explained_var: 0.20823585987091064\n",
      "        vf_loss: 0.002945664105936885\n",
      "    load_time_ms: 35.759\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 11904\n",
      "    sample_time_ms: 6513.655\n",
      "    update_time_ms: 249.168\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 172.17.0.2\n",
      "  num_healthy_workers: 1\n",
      "  off_policy_estimator: {}\n",
      "  pid: 3089\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.06810045969425645\n",
      "    mean_inference_ms: 1.1467986499833103\n",
      "    mean_processing_ms: 0.3237988132107765\n",
      "  time_since_restore: 30.33049964904785\n",
      "  time_this_iter_s: 9.58566164970398\n",
      "  time_total_s: 30.33049964904785\n",
      "  timestamp: 1569638593\n",
      "  timesteps_since_restore: 12000\n",
      "  timesteps_this_iter: 4000\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: 9d9d9a64\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/5.37 GiB heap, 0.0/1.81 GiB objects\n",
      "Memory usage on this node: 1.5/11.7 GiB\n",
      "Result logdir: /root/ray_results/PPO\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - PPO_SimpleCorridor_0:\tTERMINATED, [2 CPUs, 0 GPUs], [pid=3089], 30 s, 3 iter, 12000 ts, 1 rew\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/5.37 GiB heap, 0.0/1.81 GiB objects\n",
      "Memory usage on this node: 1.5/11.7 GiB\n",
      "Result logdir: /root/ray_results/PPO\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - PPO_SimpleCorridor_0:\tTERMINATED, [2 CPUs, 0 GPUs], [pid=3089], 30 s, 3 iter, 12000 ts, 1 rew\n",
      "\n",
      "2019-09-28 02:43:13,701\tINFO tune.py:274 -- Returning an analysis object by default. You can call `analysis.trials` to retrieve a list of trials. This message will be removed in future versions of Tune.\n"
     ]
    }
   ],
   "source": [
    "# !pip install ray \n",
    "# ray[rllib] ray[debug] pandas\n",
    "\n",
    "%cd /workspace/LearningToPaint/rllib\n",
    "!python test_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install openai baselines and other required packages\n",
    "# !pip install gym tensorflow\n",
    "\n",
    "# !apt-get update && apt-get -y install cmake libopenmpi-dev python3-dev zlib1g-dev\n",
    "# %cd /notebooks/baselines\n",
    "# # !git clone https://github.com/openai/baselines.git  # use github-desktop to clone repository\n",
    "# !pip install -e .\n",
    "\n",
    "# # install local gym-canvas as package\n",
    "# %cd /notebooks/LearningToPaint/gym-canvas\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2mAkgRjwwuf"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail\n",
      "Tuple\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 254, in <module>\n",
      "    main()\n",
      "  File \"main.py\", line 55, in main\n",
      "    base_kwargs={\"recurrent\": args.recurrent_policy},\n",
      "  File \"/notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail/a2c_ppo_acktr/model.py\", line 41, in __init__\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail\n",
    "!python main.py --env-name \"gym_canvas:canvas-v0\" --num-processes 1 --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-steps 5 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01\n",
    "\n",
    "# !python baseline/train_renderer.py\n",
    "# !tensorboard --logdir train_log --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train RL\n",
    "\n",
    "* make data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory './model': File exists\n",
      "Renderer model loaded.\n",
      "observation_space (1, 128, 128, 7) action_space 13\n",
      "\u001b[98m #0: steps:4 interval_time:0.22 train_time:24.56\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000007: mean_reward:0.288 mean_dist:0.201 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #1: steps:8 interval_time:2.69 train_time:34.23\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000011: mean_reward:-8.902 mean_dist:0.619 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #2: steps:12 interval_time:2.55 train_time:43.24\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000015: mean_reward:-7.753 mean_dist:0.417 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #3: steps:16 interval_time:2.68 train_time:55.46\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000019: mean_reward:-1.631 mean_dist:0.326 var_dist:0.000\u001b[00m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python baseline/train.py --max_step=4 --env_batch=1 --warmup=1 --validate_interval=1 --debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renderer model loaded.\n",
      "step 0: loss 9167.975586\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"baseline/train_supervised.py\", line 84, in <module>\n",
      "    train(args.batch_size, args.episode_steps)"
     ]
    }
   ],
   "source": [
    "!python baseline/train_supervised.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "learningtopaint.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
