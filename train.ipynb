{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "```bash\n",
    "sudo docker build -t maskrcnn-benchmark .\n",
    "sudo docker run \n",
    "    --runtime=nvidia -d -it \\\n",
    "    --name=maskrcnn \\\n",
    "    -v=$(pwd):/notebooks \\\n",
    "    -p=8888:8888 \\\n",
    "    --ipc=\"host\" \\\n",
    "    maskrcnn-benchmark\n",
    "sudo docker logs maskrcnn\n",
    "sudo docker start maskrcnn\n",
    "sudo docker exec -it maskrcnn /bin/bash\n",
    "```\n",
    "\n",
    "## Notes\n",
    "\n",
    "model-free vs model-based: model包含actor & critic，在critic方面，model-based有含renderer net, model-free沒有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/LearningToPaint/rllib\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 16:21:25.208178 140305200740096 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2019-08-26 16:21:26,751\tINFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-08-26_16-21-26_750709_19371/logs.\n",
      "2019-08-26 16:21:26,941\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:60619 to respond...\n",
      "2019-08-26 16:21:27,146\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:19936 to respond...\n",
      "2019-08-26 16:21:27,152\tINFO services.py:809 -- Starting Redis shard with 1.67 GB max memory.\n",
      "2019-08-26 16:21:27,389\tINFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-08-26_16-21-26_750709_19371/logs.\n",
      "2019-08-26 16:21:27,393\tWARNING services.py:1330 -- WARNING: The default object store size of 2.51 GB will use more than 50% of the available memory on this node (3.04 GB). Consider setting the object store memory manually to a smaller size to avoid memory contention with other applications.\n",
      "2019-08-26 16:21:27,404\tINFO services.py:1475 -- Starting the Plasma object store with 2.51 GB memory using /dev/shm.\n",
      "2019-08-26 16:21:27,887\tINFO trial_runner.py:176 -- Starting a new experiment.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.3/8.4 GB\n",
      "\n",
      "2019-08-26 16:21:28,012\tWARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.\n",
      "W0826 16:21:28.244618 140305200740096 deprecation_wrapper.py:119] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/logger.py:133: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.\n",
      "\n",
      "W0826 16:21:28.262458 140305200740096 deprecation_wrapper.py:119] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/logger.py:138: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "2019-08-26 16:21:28,292\tERROR log_sync.py:34 -- Log sync requires cluster to be setup with `ray up`.\n",
      "2019-08-26 16:21:28,659\tWARNING util.py:145 -- The `start_trial` operation took 0.703547477722168 seconds to complete, which may be a performance bottleneck.\n",
      "2019-08-26 16:21:28,881\tWARNING util.py:145 -- The `experiment_checkpoint` operation took 0.2161264419555664 seconds to complete, which may be a performance bottleneck.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2/2 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.4/8.4 GB\n",
      "Result logdir: /root/ray_results/PPO\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_CanvasEnv_0:\tRUNNING\n",
      "\n",
      "2019-08-26 16:21:29,015\tWARNING util.py:145 -- The `on_step_begin` operation took 0.10238289833068848 seconds to complete, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=19413)\u001b[0m WARNING: Logging before flag parsing goes to stderr.\n",
      "\u001b[2m\u001b[36m(pid=19413)\u001b[0m W0826 16:21:42.362919 140144056801024 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=19413)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=19413)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=19413)\u001b[0m 2019-08-26 16:21:44,031\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=19413)\u001b[0m 2019-08-26 16:21:44.032654: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=19413)\u001b[0m 2019-08-26 16:21:44.046131: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1296000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=19413)\u001b[0m 2019-08-26 16:21:44.046530: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564ddda6d140 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=19413)\u001b[0m 2019-08-26 16:21:44.046874: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "\u001b[2m\u001b[36m(pid=19413)\u001b[0m {'obs': OrderedDict([('cur_im', <tf.Tensor 'default_policy/Reshape:0' shape=(?, 1, 64, 64) dtype=float32>), ('obj_status', <tf.Tensor 'default_policy/Reshape_1:0' shape=(?, 4) dtype=float32>), ('target_im', <tf.Tensor 'default_policy/Reshape_2:0' shape=(?, 1, 64, 64) dtype=float32>)]), 'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 3) dtype=float32>, 'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>, 'is_training': <tf.Tensor 'default_policy/PlaceholderWithDefault:0' shape=() dtype=bool>, 'obs_flat': <tf.Tensor 'default_policy/observation:0' shape=(?, 8196) dtype=float32>}\n",
      "2019-08-26 16:21:45,072\tERROR trial_runner.py:550 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 498, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 342, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/worker.py\", line 2247, in get\n",
      "    raise value\n",
      "ray.exceptions.RayTaskError: \u001b[36mray_PPO:train()\u001b[39m (pid=19413, host=714a8423a409)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py\", line 87, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 328, in __init__\n",
      "    Trainable.__init__(self, config, logger_creator)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/trainable.py\", line 99, in __init__\n",
      "    self._setup(copy.deepcopy(self.config))\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 443, in _setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py\", line 106, in _init\n",
      "    self.config[\"num_workers\"])\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/agents/trainer.py\", line 488, in _make_workers\n",
      "    logdir=self.logdir)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py\", line 64, in __init__\n",
      "    RolloutWorker, env_creator, policy, 0, self._local_config)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py\", line 216, in _make_worker\n",
      "    _fake_sampler=config.get(\"_fake_sampler\", False))\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 334, in __init__\n",
      "    self._build_policy_map(policy_dict, policy_config)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 738, in _build_policy_map\n",
      "    policy_map[name] = cls(obs_space, act_space, merged_conf)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/policy/tf_policy_template.py\", line 144, in __init__\n",
      "    obs_include_prev_action_reward=obs_include_prev_action_reward)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 158, in __init__\n",
      "    self.input_dict, self.state_in, self.seq_lens)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/modelv2.py\", line 148, in __call__\n",
      "    res = self.forward(restored, state or [], seq_lens)\n",
      "  File \"canvas_env.py\", line 212, in forward\n",
      "    return self.model.forward(input_dict, state, seq_lens)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/fcnet_v2.py\", line 83, in forward\n",
      "    model_out, self._value_out = self.base_model(input_dict[\"obs\"])\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 634, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 751, in call\n",
      "    return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\", line 893, in _run_internal_graph\n",
      "    output_tensors = layer(computed_tensors, **kwargs)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 586, in __call__\n",
      "    self.name)\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py\", line 159, in assert_input_compatibility\n",
      "    ' but received input with shape ' + str(shape))\n",
      "ValueError: Input 0 of layer fc_1 is incompatible with the layer: expected axis -1 of input shape to have value 8196 but received input with shape [None, 1, 64, 64]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\r\n",
      "Using FIFO scheduling algorithm.\r\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs\r\n",
      "Memory usage on this node: 5.6/8.4 GB\r\n",
      "Result logdir: /root/ray_results/PPO\r\n",
      "Number of trials: 1 ({'ERROR': 1})\r\n",
      "ERROR trials:\r\n",
      " - PPO_CanvasEnv_0:\tERROR, 1 failures: /root/ray_results/PPO/PPO_CanvasEnv_0_2019-08-26_16-21-28v3tmzxb8/error_2019-08-26_16-21-45.txt\r\n",
      "\r\n",
      "== Status ==\r\n",
      "Using FIFO scheduling algorithm.\r\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs\r\n",
      "Memory usage on this node: 5.6/8.4 GB\r\n",
      "Result logdir: /root/ray_results/PPO\r\n",
      "Number of trials: 1 ({'ERROR': 1})\r\n",
      "ERROR trials:\r\n",
      " - PPO_CanvasEnv_0:\tERROR, 1 failures: /root/ray_results/PPO/PPO_CanvasEnv_0_2019-08-26_16-21-28v3tmzxb8/error_2019-08-26_16-21-45.txt\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"canvas_env.py\", line 231, in <module>\r\n",
      "    \"num_workers\": 1,  # parallelism\r\n",
      "  File \"/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/tune.py\", line 262, in run\r\n",
      "    raise TuneError(\"Trials did not complete\", errored_trials)\r\n",
      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_CanvasEnv_0])\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install ray \n",
    "# ray[rllib] ray[debug] pandas\n",
    "\n",
    "%cd /notebooks/LearningToPaint/rllib\n",
    "!python canvas_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/LearningToPaint/gym-canvas\n",
      "Obtaining file:///notebooks/LearningToPaint/gym-canvas\n",
      "Requirement already satisfied: gym in /miniconda/envs/py36/lib/python3.6/site-packages (from gym-canvas==0.0.1) (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /miniconda/envs/py36/lib/python3.6/site-packages (from gym->gym-canvas==0.0.1) (1.16.3)\n",
      "Requirement already satisfied: scipy in /miniconda/envs/py36/lib/python3.6/site-packages (from gym->gym-canvas==0.0.1) (1.3.0)\n",
      "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /miniconda/envs/py36/lib/python3.6/site-packages (from gym->gym-canvas==0.0.1) (1.3.2)\n",
      "Requirement already satisfied: six in /miniconda/envs/py36/lib/python3.6/site-packages (from gym->gym-canvas==0.0.1) (1.12.0)\n",
      "Requirement already satisfied: cloudpickle~=1.2.0 in /miniconda/envs/py36/lib/python3.6/site-packages (from gym->gym-canvas==0.0.1) (1.2.1)\n",
      "Requirement already satisfied: future in /miniconda/envs/py36/lib/python3.6/site-packages (from pyglet<=1.3.2,>=1.2.0->gym->gym-canvas==0.0.1) (0.17.1)\n",
      "Installing collected packages: gym-canvas\n",
      "  Found existing installation: gym-canvas 0.0.1\n",
      "    Uninstalling gym-canvas-0.0.1:\n",
      "      Successfully uninstalled gym-canvas-0.0.1\n",
      "  Running setup.py develop for gym-canvas\n",
      "Successfully installed gym-canvas\n"
     ]
    }
   ],
   "source": [
    "# install openai baselines and other required packages\n",
    "# !pip install gym tensorflow\n",
    "\n",
    "# !apt-get update && apt-get -y install cmake libopenmpi-dev python3-dev zlib1g-dev\n",
    "# %cd /notebooks/baselines\n",
    "# # !git clone https://github.com/openai/baselines.git  # use github-desktop to clone repository\n",
    "# !pip install -e .\n",
    "\n",
    "# # install local gym-canvas as package\n",
    "# %cd /notebooks/LearningToPaint/gym-canvas\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2mAkgRjwwuf"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail\n",
      "Tuple\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 254, in <module>\n",
      "    main()\n",
      "  File \"main.py\", line 55, in main\n",
      "    base_kwargs={\"recurrent\": args.recurrent_policy},\n",
      "  File \"/notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail/a2c_ppo_acktr/model.py\", line 41, in __init__\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail\n",
    "!python main.py --env-name \"gym_canvas:canvas-v0\" --num-processes 1 --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-steps 5 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01\n",
    "\n",
    "# !python baseline/train_renderer.py\n",
    "# !tensorboard --logdir train_log --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train RL\n",
    "\n",
    "* make data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory './model': File exists\n",
      "Renderer model loaded.\n",
      "observation_space (1, 128, 128, 7) action_space 13\n",
      "\u001b[98m #0: steps:4 interval_time:0.22 train_time:24.56\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000007: mean_reward:0.288 mean_dist:0.201 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #1: steps:8 interval_time:2.69 train_time:34.23\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000011: mean_reward:-8.902 mean_dist:0.619 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #2: steps:12 interval_time:2.55 train_time:43.24\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000015: mean_reward:-7.753 mean_dist:0.417 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #3: steps:16 interval_time:2.68 train_time:55.46\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000019: mean_reward:-1.631 mean_dist:0.326 var_dist:0.000\u001b[00m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python baseline/train.py --max_step=4 --env_batch=1 --warmup=1 --validate_interval=1 --debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renderer model loaded.\n",
      "step 0: loss 9167.975586\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"baseline/train_supervised.py\", line 84, in <module>\n",
      "    train(args.batch_size, args.episode_steps)"
     ]
    }
   ],
   "source": [
    "!python baseline/train_supervised.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "learningtopaint.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
