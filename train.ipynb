{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "```bash\n",
    "sudo docker build -t maskrcnn-benchmark .\n",
    "sudo docker run \n",
    "    --runtime=nvidia -d -it \\\n",
    "    --name=maskrcnn \\\n",
    "    -v=$(pwd):/notebooks \\\n",
    "    -p=8888:8888 \\\n",
    "    --ipc=\"host\" \\\n",
    "    maskrcnn-benchmark\n",
    "sudo docker logs maskrcnn\n",
    "sudo docker start maskrcnn\n",
    "sudo docker exec -it maskrcnn /bin/bash\n",
    "```\n",
    "\n",
    "## Notes\n",
    "\n",
    "model-free vs model-based: model包含actor & critic，在critic方面，model-based有含renderer net, model-free沒有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-21 15:44:01,520\tINFO trial_runner.py:176 -- Starting a new experiment.\n",
      "2019-08-21 15:44:01,546\tWARNING ray_trial_executor.py:449 -- Allowing trial to start even though the cluster does not have enough free resources. Trial actors may appear to hang until enough resources are added to the cluster (e.g., via autoscaling). You can disable this behavior by specifying `queue_trials=False` in ray.tune.run().\n",
      "2019-08-21 15:44:01,592\tWARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.\n",
      "W0821 15:44:01.610119 140592725792512 deprecation_wrapper.py:119] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/logger.py:133: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.\n",
      "\n",
      "W0821 15:44:01.619529 140592725792512 deprecation_wrapper.py:119] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/logger.py:138: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "2019-08-21 15:44:01,638\tERROR log_sync.py:34 -- Log sync requires cluster to be setup with `ray up`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 2.1/8.4 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-21 15:44:01,740\tWARNING util.py:145 -- The `start_trial` operation took 0.17166757583618164 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 3/2 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 2.1/8.4 GB\n",
      "Result logdir: /root/ray_results/PPO\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - PPO_CartPole-v0_0:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m WARNING: Logging before flag parsing goes to stderr.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m W0821 15:44:05.600501 140552880195328 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:06,228\tWARNING ppo.py:143 -- FYI: By default, the value function will not share layers with the policy model ('vf_share_layers': False).\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:06,262\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:06.267825: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:06.332675: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1296000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:06.335136: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b2811d55a0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:06.335274: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m W0821 15:44:06.360538 140552880195328 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m Use keras.layers.dense instead.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m W0821 15:44:06.905250 140552880195328 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:77: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m Use `tf.random.categorical` instead.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:07.073241: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:07,160\tINFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?,) dtype=int64>,\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 4) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 4) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?,) dtype=int64>,\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m W0821 15:44:07.188395 140552880195328 deprecation.py:506] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:64: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m keep_dims is deprecated, use keepdims instead\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m W0821 15:44:07.202013 140552880195328 deprecation.py:506] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:69: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m keep_dims is deprecated, use keepdims instead\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m W0821 15:44:07.291238 140552880195328 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:09,697\tINFO rollout_worker.py:742 -- Built policy map: {'default_policy': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x7fd4800275c0>}\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:09,697\tINFO rollout_worker.py:743 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fd4800274e0>}\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:09,697\tINFO rollout_worker.py:356 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7fd480027400>}\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:09,785\tINFO multi_gpu_optimizer.py:93 -- LocalMultiGPUOptimizer devices ['/cpu:0']\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m WARNING: Logging before flag parsing goes to stderr.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m W0821 15:44:14.614343 140260827129600 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:15,630\tINFO rollout_worker.py:319 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:15.677059: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:15.686955: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1296000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:15.688297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x565497f78db0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:15.688445: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m W0821 15:44:15.700066 140260827129600 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/fcnet_v1.py:48: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m W0821 15:44:16.705752 140260827129600 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:77: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m Use `tf.random.categorical` instead.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m 2019-08-21 15:44:16,885\tINFO trainable.py:105 -- _setup took 10.715 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m W0821 15:44:16.895627 140552880195328 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12886)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:17.102660: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:17,144\tINFO dynamic_tf_policy.py:324 -- Initializing loss function with dummy input:\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?,) dtype=int64>,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 2) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 4) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 4) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?,) dtype=int64>,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m W0821 15:44:17.164976 140260827129600 deprecation.py:506] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:64: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m keep_dims is deprecated, use keepdims instead\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m W0821 15:44:17.171748 140260827129600 deprecation.py:506] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/models/tf/tf_action_dist.py:69: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m keep_dims is deprecated, use keepdims instead\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m W0821 15:44:17.231591 140260827129600 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m W0821 15:44:19.896920 140260827129600 deprecation.py:323] From /miniconda/envs/py36/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:570: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:20,060\tINFO rollout_worker.py:451 -- Generating sample batch of size 200\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:20,065\tINFO sampler.py:304 -- Raw obs from env: { 0: { 'agent0': np.ndarray((4,), dtype=float64, min=-0.047, max=0.039, mean=-0.011)}}\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:20,065\tINFO sampler.py:305 -- Info return from env: {0: {'agent0': None}}\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:20,066\tINFO sampler.py:403 -- Preprocessed obs: np.ndarray((4,), dtype=float64, min=-0.047, max=0.039, mean=-0.011)\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:20,067\tINFO sampler.py:407 -- Filtered obs: np.ndarray((4,), dtype=float64, min=-0.047, max=0.039, mean=-0.011)\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:20,069\tINFO sampler.py:521 -- Inputs to compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                                   'env_id': 0,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                                   'info': None,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                                   'obs': np.ndarray((4,), dtype=float64, min=-0.047, max=0.039, mean=-0.011),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                                   'prev_action': np.ndarray((), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                                   'prev_reward': 0.0,\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                                   'rnn_state': []},\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'type': 'PolicyEvalData'}]}\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:20,070\tINFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:20,157\tINFO sampler.py:548 -- Outputs of compute_actions():\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m { 'default_policy': ( np.ndarray((1,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                       [],\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                       { 'action_prob': np.ndarray((1,), dtype=float32, min=0.5, max=0.5, mean=0.5),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'behaviour_logits': np.ndarray((1, 2), dtype=float32, min=-0.0, max=-0.0, mean=-0.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=-0.0, max=-0.0, mean=-0.0)})}\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:20,245\tINFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m { 'agent0': { 'data': { 'action_prob': np.ndarray((21,), dtype=float32, min=0.499, max=0.501, mean=0.5),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'actions': np.ndarray((21,), dtype=int64, min=0.0, max=1.0, mean=0.524),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'advantages': np.ndarray((21,), dtype=float32, min=1.001, max=19.027, mean=10.301),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'agent_index': np.ndarray((21,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'behaviour_logits': np.ndarray((21, 2), dtype=float32, min=-0.001, max=0.003, mean=0.001),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'dones': np.ndarray((21,), dtype=bool, min=0.0, max=1.0, mean=0.048),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'eps_id': np.ndarray((21,), dtype=int64, min=146156922.0, max=146156922.0, mean=146156922.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'infos': np.ndarray((21,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'new_obs': np.ndarray((21, 4), dtype=float32, min=-1.338, max=0.642, mean=-0.087),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'obs': np.ndarray((21, 4), dtype=float32, min=-1.338, max=0.642, mean=-0.079),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'prev_actions': np.ndarray((21,), dtype=int64, min=0.0, max=1.0, mean=0.524),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'prev_rewards': np.ndarray((21,), dtype=float32, min=0.0, max=1.0, mean=0.952),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'rewards': np.ndarray((21,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         't': np.ndarray((21,), dtype=int64, min=0.0, max=20.0, mean=10.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'unroll_id': np.ndarray((21,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'value_targets': np.ndarray((21,), dtype=float32, min=1.0, max=19.027, mean=10.3),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m                         'vf_preds': np.ndarray((21,), dtype=float32, min=-0.001, max=0.0, mean=-0.001)},\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m               'type': 'SampleBatch'}}\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m 2019-08-21 15:44:20,673\tINFO rollout_worker.py:485 -- Completed sample batch:\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m { 'data': { 'action_prob': np.ndarray((200,), dtype=float32, min=0.499, max=0.501, mean=0.5),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'actions': np.ndarray((200,), dtype=int64, min=0.0, max=1.0, mean=0.5),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'advantages': np.ndarray((200,), dtype=float32, min=0.998, max=30.359, mean=10.845),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'agent_index': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'behaviour_logits': np.ndarray((200, 2), dtype=float32, min=-0.003, max=0.004, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'dones': np.ndarray((200,), dtype=bool, min=0.0, max=1.0, mean=0.045),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'eps_id': np.ndarray((200,), dtype=int64, min=12743381.0, max=1705473966.0, mean=525780334.415),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'infos': np.ndarray((200,), dtype=object, head={}),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'new_obs': np.ndarray((200, 4), dtype=float32, min=-1.89, max=2.542, mean=-0.026),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'obs': np.ndarray((200, 4), dtype=float32, min=-1.89, max=2.201, mean=-0.024),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'prev_actions': np.ndarray((200,), dtype=int64, min=0.0, max=1.0, mean=0.485),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'prev_rewards': np.ndarray((200,), dtype=float32, min=0.0, max=1.0, mean=0.95),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'rewards': np.ndarray((200,), dtype=float32, min=1.0, max=1.0, mean=1.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             't': np.ndarray((200,), dtype=int64, min=0.0, max=35.0, mean=10.72),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'unroll_id': np.ndarray((200,), dtype=int64, min=0.0, max=0.0, mean=0.0),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'value_targets': np.ndarray((200,), dtype=float32, min=1.0, max=30.359, mean=10.845),\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m             'vf_preds': np.ndarray((200,), dtype=float32, min=-0.002, max=0.002, mean=-0.0)},\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m   'type': 'SampleBatch'}\n",
      "\u001b[2m\u001b[36m(pid=12887)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-22 12:25:13,984\tERROR import_thread.py:89 -- ImportThread: Connection closed by server.\n",
      "2019-08-22 12:25:14,101\tERROR worker.py:1716 -- listen_error_messages_raylet: Connection closed by server.\n",
      "2019-08-22 12:25:13,908\tERROR worker.py:1616 -- print_logs: Connection closed by server.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-71a29a55b68e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPPOTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPPOTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"env\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"CartPole-v0\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, restore, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init, sync_function)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mlast_debug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_debug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mDEBUG_PRINT_INTERVAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/envs/py36/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/miniconda/envs/py36/lib/python3.6/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_ids, num_returns, timeout)\u001b[0m\n\u001b[1;32m   2370\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m             \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2373\u001b[0m         )\n\u001b[1;32m   2374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.RayletClient.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/miniconda/envs/py36/lib/python3.6/site-packages/ray/exceptions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, client_exc)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_exc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_exc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# !pip install ray \n",
    "# ray[rllib] ray[debug] pandas\n",
    "\n",
    "# !rllib train --run=PPO --env=CartPole-v0\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "\n",
    "tune.run(PPOTrainer, config={\"env\": \"CartPole-v0\"}, queue_trials=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/LearningToPaint/gym-canvas\n",
      "Obtaining file:///notebooks/LearningToPaint/gym-canvas\n",
      "Requirement already satisfied: gym in /miniconda/envs/py36/lib/python3.6/site-packages (from gym-canvas==0.0.1) (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /miniconda/envs/py36/lib/python3.6/site-packages (from gym->gym-canvas==0.0.1) (1.16.3)\n",
      "Requirement already satisfied: scipy in /miniconda/envs/py36/lib/python3.6/site-packages (from gym->gym-canvas==0.0.1) (1.3.0)\n",
      "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /miniconda/envs/py36/lib/python3.6/site-packages (from gym->gym-canvas==0.0.1) (1.3.2)\n",
      "Requirement already satisfied: six in /miniconda/envs/py36/lib/python3.6/site-packages (from gym->gym-canvas==0.0.1) (1.12.0)\n",
      "Requirement already satisfied: cloudpickle~=1.2.0 in /miniconda/envs/py36/lib/python3.6/site-packages (from gym->gym-canvas==0.0.1) (1.2.1)\n",
      "Requirement already satisfied: future in /miniconda/envs/py36/lib/python3.6/site-packages (from pyglet<=1.3.2,>=1.2.0->gym->gym-canvas==0.0.1) (0.17.1)\n",
      "Installing collected packages: gym-canvas\n",
      "  Found existing installation: gym-canvas 0.0.1\n",
      "    Uninstalling gym-canvas-0.0.1:\n",
      "      Successfully uninstalled gym-canvas-0.0.1\n",
      "  Running setup.py develop for gym-canvas\n",
      "Successfully installed gym-canvas\n"
     ]
    }
   ],
   "source": [
    "# install openai baselines and other required packages\n",
    "# !pip install gym tensorflow\n",
    "\n",
    "# !apt-get update && apt-get -y install cmake libopenmpi-dev python3-dev zlib1g-dev\n",
    "# %cd /notebooks/baselines\n",
    "# # !git clone https://github.com/openai/baselines.git  # use github-desktop to clone repository\n",
    "# !pip install -e .\n",
    "\n",
    "# # install local gym-canvas as package\n",
    "# %cd /notebooks/LearningToPaint/gym-canvas\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2mAkgRjwwuf"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail\n",
      "Tuple\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 254, in <module>\n",
      "    main()\n",
      "  File \"main.py\", line 55, in main\n",
      "    base_kwargs={\"recurrent\": args.recurrent_policy},\n",
      "  File \"/notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail/a2c_ppo_acktr/model.py\", line 41, in __init__\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks/LearningToPaint/pytorch-a2c-ppo-acktr-gail\n",
    "!python main.py --env-name \"gym_canvas:canvas-v0\" --num-processes 1 --algo ppo --use-gae --lr 2.5e-4 --clip-param 0.1 --value-loss-coef 0.5 --num-steps 5 --num-mini-batch 4 --log-interval 1 --use-linear-lr-decay --entropy-coef 0.01\n",
    "\n",
    "# !python baseline/train_renderer.py\n",
    "# !tensorboard --logdir train_log --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train RL\n",
    "\n",
    "* make data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory './model': File exists\n",
      "Renderer model loaded.\n",
      "observation_space (1, 128, 128, 7) action_space 13\n",
      "\u001b[98m #0: steps:4 interval_time:0.22 train_time:24.56\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000007: mean_reward:0.288 mean_dist:0.201 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #1: steps:8 interval_time:2.69 train_time:34.23\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000011: mean_reward:-8.902 mean_dist:0.619 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #2: steps:12 interval_time:2.55 train_time:43.24\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000015: mean_reward:-7.753 mean_dist:0.417 var_dist:0.000\u001b[00m\n",
      "\u001b[98m #3: steps:16 interval_time:2.68 train_time:55.46\u001b[00m\n",
      "evaluating\n",
      "\u001b[91m Step_0000019: mean_reward:-1.631 mean_dist:0.326 var_dist:0.000\u001b[00m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python baseline/train.py --max_step=4 --env_batch=1 --warmup=1 --validate_interval=1 --debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renderer model loaded.\n",
      "step 0: loss 9167.975586\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"baseline/train_supervised.py\", line 84, in <module>\n",
      "    train(args.batch_size, args.episode_steps)"
     ]
    }
   ],
   "source": [
    "!python baseline/train_supervised.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "learningtopaint.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
